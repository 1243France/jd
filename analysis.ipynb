{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "action_1_path = \"./data/JData_Action_201602.csv\"\n",
    "action_2_path = \"./data/JData_Action_201603.csv\"\n",
    "action_2_extra_path = \"./data/JData_Action_201603_extra.csv\"\n",
    "action_3_path = \"./data/JData_Action_201604.csv\"\n",
    "comment_path = \"./data/JData_Comment(修正版).csv\"\n",
    "product_path = \"./data/JData_Product.csv\"\n",
    "user_path = \"./data/JData_User.csv\"\n",
    "\n",
    "action_1 = pd.read_csv(action_1_path)\n",
    "action_2 = pd.read_csv(action_2_path)\n",
    "action_3 = pd.read_csv(action_3_path)\n",
    "action_2_extra = pd.read_csv(action_2_extra_path)\n",
    "comment = pd.read_csv(comment_path)\n",
    "product = pd.read_csv(product_path)\n",
    "user = pd.read_csv(user_path, encoding='gbk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_user_feat():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>user_lv_cd</th>\n",
       "      <th>user_reg_dt</th>\n",
       "      <th>age_-1</th>\n",
       "      <th>age_15岁以下</th>\n",
       "      <th>age_16-25岁</th>\n",
       "      <th>age_26-35岁</th>\n",
       "      <th>age_36-45岁</th>\n",
       "      <th>age_46-55岁</th>\n",
       "      <th>age_56岁以上</th>\n",
       "      <th>sex_0</th>\n",
       "      <th>sex_1</th>\n",
       "      <th>sex_2</th>\n",
       "      <th>user_lv_cd_1</th>\n",
       "      <th>user_lv_cd_2</th>\n",
       "      <th>user_lv_cd_3</th>\n",
       "      <th>user_lv_cd_4</th>\n",
       "      <th>user_lv_cd_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2016/1/26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79</td>\n",
       "      <td>36-45岁</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2016/1/27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>16-25岁</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2016/1/27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>266</td>\n",
       "      <td>15岁以下</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2016/1/29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>333</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2016/1/30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id     age  sex  user_lv_cd user_reg_dt  age_-1  age_15岁以下  \\\n",
       "0       54      -1    2           1   2016/1/26     1.0        0.0   \n",
       "1       79  36-45岁    2           2   2016/1/27     0.0        0.0   \n",
       "2      100  16-25岁    2           3   2016/1/27     0.0        0.0   \n",
       "3      266   15岁以下    2           2   2016/1/29     0.0        1.0   \n",
       "4      333      -1    2           4   2016/1/30     1.0        0.0   \n",
       "\n",
       "   age_16-25岁  age_26-35岁  age_36-45岁  age_46-55岁  age_56岁以上  sex_0  sex_1  \\\n",
       "0         0.0         0.0         0.0         0.0        0.0    0.0    0.0   \n",
       "1         0.0         0.0         1.0         0.0        0.0    0.0    0.0   \n",
       "2         1.0         0.0         0.0         0.0        0.0    0.0    0.0   \n",
       "3         0.0         0.0         0.0         0.0        0.0    0.0    0.0   \n",
       "4         0.0         0.0         0.0         0.0        0.0    0.0    0.0   \n",
       "\n",
       "   sex_2  user_lv_cd_1  user_lv_cd_2  user_lv_cd_3  user_lv_cd_4  user_lv_cd_5  \n",
       "0    1.0           1.0           0.0           0.0           0.0           0.0  \n",
       "1    1.0           0.0           1.0           0.0           0.0           0.0  \n",
       "2    1.0           0.0           0.0           1.0           0.0           0.0  \n",
       "3    1.0           0.0           1.0           0.0           0.0           0.0  \n",
       "4    1.0           0.0           0.0           0.0           1.0           0.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 用户数量 103616 \n",
    "\n",
    "pd.get_dummies(user[\"age\"])\n",
    "age_df = pd.get_dummies(user[\"age\"], prefix=\"age\", columns=[\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\"])\n",
    "sex_df = pd.get_dummies(user[\"sex\"], prefix=\"sex\")\n",
    "user_lv_df = pd.get_dummies(user[\"user_lv_cd\"], prefix=\"user_lv_cd\")\n",
    "user = pd.concat([user, age_df, sex_df ,user_lv_df], axis=1)\n",
    "user.head()\n",
    "#print user.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       sku_id  attr1  attr2  attr3  cate  brand\n",
      "0      166731      1     -1     -1     8    545\n",
      "1      146488      2      2     -1     8    812\n",
      "2       70546      3      1      1     8    214\n",
      "3       92487      2      2     -1     8    812\n",
      "4      113065      2      2     -1     8    812\n",
      "5       80307      2      2     -1     8    812\n",
      "6       71669      2      1     -1     8    812\n",
      "7        4145      2      2      1     8    812\n",
      "8       35450      2      2     -1     8    812\n",
      "9      131403      2      1     -1     8    812\n",
      "10     128621      2      1     -1     8    812\n",
      "11      65347      2      1      2     8    812\n",
      "12      68153      2      1      2     8    812\n",
      "13      77945      2      1     -1     8    812\n",
      "14     167028      2      1     -1     8    812\n",
      "15      14771      2      1      2     8    812\n",
      "16     153408      2      1     -1     8    812\n",
      "17      39874      2      2     -1     8    812\n",
      "18      83454      2      1     -1     8    812\n",
      "19     141684      2     -1      2     8    623\n",
      "20      78125      2      1     -1     8    812\n",
      "21     129840      2      2      2     8    623\n",
      "22      42772      2     -1      2     8    623\n",
      "23      51732      2      1      2     8    623\n",
      "24      61364      2      1     -1     8    812\n",
      "25     162019      2      2      1     8    812\n",
      "26      33786      2      1      2     8    812\n",
      "27      69751      2      2     -1     8    812\n",
      "28      80861      2      1      1     8    812\n",
      "29      35975      2     -1      2     8    812\n",
      "...       ...    ...    ...    ...   ...    ...\n",
      "24157   20168      2      2      2     8    623\n",
      "24158    7067      2      2     -1     8    623\n",
      "24159   86694      3      2      1     8    214\n",
      "24160  159345      3      1      1     8    214\n",
      "24161  171111      3      2      1     8    214\n",
      "24162   19852      3      1      1     8    214\n",
      "24163   29463      3      2      1     8    214\n",
      "24164   30805      3     -1     -1     8    214\n",
      "24165  167877      3     -1     -1     8    214\n",
      "24166   83586      3     -1     -1     8    214\n",
      "24167   54425      3     -1     -1     8    214\n",
      "24168   26123      3      1      2     8    489\n",
      "24169  127618      3      1      2     8    489\n",
      "24170   64484      3      1     -1     8    306\n",
      "24171   49835     -1     -1     -1     8     49\n",
      "24172  127766      2      1      2     8    623\n",
      "24173   17688      2      1      2     8    623\n",
      "24174  118669      2      1      2     8    124\n",
      "24175  106654      2      1      2     8    124\n",
      "24176   93873      2      1      2     8    124\n",
      "24177  112603      2      2     -1     8    812\n",
      "24178  112739     -1     -1     -1     8    383\n",
      "24179   26059     -1     -1     -1     8    383\n",
      "24180   68696     -1     -1     -1     8    383\n",
      "24181  101664      1      1      2     8    693\n",
      "24182   38128      1      1      1     8    427\n",
      "24183  110813      2      2      1     8    812\n",
      "24184   72751      2      1      1     8    812\n",
      "24185  112327      2      1      1     8    812\n",
      "24186     315      2      2      1     8    812\n",
      "\n",
      "[24187 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# 商品数量 24187 \n",
    "# 类目数量 8\n",
    "# 品牌数量 545\n",
    "print product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([545, 812, 214, 623, 124, 658, 885, 403, 321, 306, 766, 800, 489,\n",
       "       209, 244, 484, 717, 515, 285, 801, 693, 174, 562, 596, 116, 655,\n",
       "       200,  83, 837, 211, 328, 622,  48, 249,  88, 291,  90, 556, 427,\n",
       "       318, 790, 673, 370, 127, 677, 857, 263, 101,  30, 875, 605, 283,\n",
       "       479, 916, 804,  25, 594, 900,  13, 635,  14,   3, 599, 197, 571,\n",
       "        70,  51,  76, 907,  24, 404, 354, 159, 541,  91, 375, 922, 674,\n",
       "       225, 752, 180, 759, 227, 855, 331, 739, 355, 772, 905, 324, 871,\n",
       "       574, 665, 561, 299, 336, 438, 499, 453, 554,  49, 383])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product.brand.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2016-02-01 2016-02-08 2016-02-15 2016-02-22\t2016-02-29\t2016-03-07 2016-03-14 2016-03-21 2016-03-28 2016-04-04 2016-04-11 2016-04-15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def select_label(df, start_time, end_time, product):\n",
    "    df = df[(df.time >= start_time) & (df.time < end_time) &(df['type'] == 4)]\n",
    "    df = pd.merge(df, product, how='inner', on='sku_id')\n",
    "    return df\n",
    "\n",
    "def select_range(df, start_time, end_time):\n",
    "    df = df[(df.time >= start_time) & (df.time < end_time)]\n",
    "    return df\n",
    "\n",
    "\n",
    "def report(pred, label):\n",
    "    \n",
    "    actions = label\n",
    "    result = pred\n",
    "    \n",
    "        # 所有用户商品对\n",
    "    all_user_item_pair = actions['user_id'].map(str) + '-' + actions['sku_id'].map(str)\n",
    "    all_user_item_pair = np.array(all_user_item_pair)\n",
    "    # 所有购买用户\n",
    "    all_user_set = actions['user_id'].unique()\n",
    "    \n",
    "    \n",
    "    # 所有品类中预测购买的用户\n",
    "    all_user_test_set = result['user_id'].unique()\n",
    "    all_user_test_item_pair = result['user_id'].map(str) + '-' + result['sku_id'].map(str)\n",
    "    all_user_test_item_pair = np.array(all_user_test_item_pair)\n",
    "    \n",
    "\n",
    "    #计算所有用户购买评价指标\n",
    "    pos, neg = 0,0\n",
    "    for user_id in all_user_test_set:\n",
    "        if user_id in all_user_set:\n",
    "            pos += 1\n",
    "        else:\n",
    "            neg += 1\n",
    "    all_user_acc = 1.0 * pos / ( pos + neg)\n",
    "    all_user_recall = 1.0 * pos / len(all_user_set)\n",
    "    print '所有用户中预测购买用户的准确率为 ' + str(all_user_acc)\n",
    "    print '所有用户中预测购买用户的召回率' + str(all_user_recall)\n",
    "    \n",
    "    pos, neg = 0, 0\n",
    "    for user_item_pair in all_user_test_item_pair:\n",
    "        if user_item_pair in all_user_item_pair:\n",
    "            pos += 1\n",
    "        else:\n",
    "            neg += 1\n",
    "    all_item_acc = 1.0 * pos / ( pos + neg)\n",
    "    all_item_recall = 1.0 * pos / len(all_user_item_pair)\n",
    "    print '所有用户中预测购买商品的准确率为 ' + str(all_item_acc)\n",
    "    print '所有用户中预测购买商品的召回率' + str(all_item_recall)\n",
    "    F11 = 6.0 * all_user_recall * all_user_acc / (5.0 * all_user_recall + all_user_acc)\n",
    "    F12 = 5.0 * all_item_acc * all_item_recall / (2.0 * all_item_recall + 3 * all_item_acc)\n",
    "    score = 0.4 * F11 + 0.6 * F12\n",
    "    print 'F11=' + str(F11)\n",
    "    print 'F12=' + str(F12)\n",
    "    print 'score=' + str(score)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_time = [\"2016-02-01\", \"2016-02-08\", \"2016-02-15\", \"2016-02-22\", \"2016-02-29\", \"2016-03-07\", \"2016-03-14\", \"2016-03-21\", \"2016-03-28\", \n",
    "              \"2016-04-04\", \"2016-04-11\", \"2016-04-15\"]\n",
    "\n",
    "# 下单\n",
    "# all_test_actions = action_1[(action_1.time >= start_time[2]) & (action_1.time < start_time[3]) & ((action_1['type'] == 2) | (action_1['type'] == 5))]\n",
    "\n",
    "all_test_actions = action_1[(action_1.time >= start_time[2]) & (action_1.time < start_time[3]) & (action_1['type'] == 2)]\n",
    "# 购买\n",
    "all_real_actions = action_1[(action_1.time >= start_time[3]) & (action_1.time < start_time[4]) & (action_1['type'] == 4)]\n",
    "\n",
    "report(all_test_actions, all_real_actions)\n",
    "\n",
    "test_actions = all_test_actions.groupby(['user_id', 'sku_id'])['time'].agg({'no':'count'}).reset_index().sort_values(by='no',ascending=False).groupby('user_id').first()\n",
    "\n",
    "test_actions = test_actions.reset_index()\n",
    "\n",
    "# 下单\n",
    "test_actions = pd.merge(test_actions, product, how='inner', on='sku_id')\n",
    "\n",
    "# 购买\n",
    "real_actions = pd.merge(all_real_actions, product, how='inner', on='sku_id')\n",
    "\n",
    "report(test_actions, real_actions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "action_reg = action_3[(action_3.time >= '2016-04-13') & (action_3.time < '2016-04-16') & (action_3['type'] == 2)]\n",
    "A = action_reg.groupby(['user_id', 'sku_id'])['time'].agg({'no':'count'}).reset_index().sort_values(by='no',ascending=False).groupby('user_id').first()\n",
    "A_clean = A.reset_index()[['user_id', 'sku_id']]\n",
    "B = product\n",
    "A_B = pd.merge(A_clean, B, how='inner', on='sku_id')\n",
    "A_B[['user_id', 'sku_id']].to_csv('submision.csv', index=False)\n",
    "\n",
    "#action_reg.groupby(['user_id', 'sku_id']).count().reset_index()[['user_id', 'sku_id']].to_csv('submisson.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'hello'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from datetime import datetime\n",
    "import math\n",
    "\n",
    "def encode_onehot(df, cols):\n",
    "    \"\"\"\n",
    "    One-hot encoding is applied to columns specified in a pandas DataFrame.\n",
    "    \n",
    "    Modified from: https://gist.github.com/kljensen/5452382\n",
    "    \n",
    "    Details:\n",
    "    \n",
    "    http://en.wikipedia.org/wiki/One-hot\n",
    "    http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\n",
    "    \n",
    "    @param df pandas DataFrame\n",
    "    @param cols a list of columns to encode\n",
    "    @return a DataFrame with one-hot encoding\n",
    "    \"\"\"\n",
    "    vec = DictVectorizer()\n",
    "    \n",
    "    vec_data = pd.DataFrame(vec.fit_transform(df[cols].to_dict(orient='records')).toarray())\n",
    "    vec_data.columns = vec.get_feature_names()\n",
    "    vec_data.index = df.index\n",
    "    \n",
    "    df = df.drop(cols, axis=1)\n",
    "    df = df.join(vec_data)\n",
    "    return df\n",
    "\n",
    "def weighted(cols):\n",
    "    cols['action_1'] = sum(cols['action_1'] * cols['weights'])\n",
    "    cols['action_2'] = sum(cols['action_2'] * cols['weights'])\n",
    "    cols['action_3'] = sum(cols['action_3'] * cols['weights'])\n",
    "    cols['action_4'] = sum(cols['action_4'] * cols['weights'])\n",
    "    cols['action_5'] = sum(cols['action_5'] * cols['weights'])\n",
    "    cols['action_6'] = sum(cols['action_6'] * cols['weights'])\n",
    "    return cols\n",
    "    \n",
    "    \n",
    "def make_train_set(train_start_date, train_end_date, test_end_date, actions, user, comment):\n",
    "    \n",
    "    comment_date = [\"2016-02-01\", \"2016-02-08\", \"2016-02-15\", \"2016-02-22\", \"2016-02-29\", \"2016-03-07\", \"2016-03-14\", \"2016-03-21\", \"2016-03-28\", \n",
    "              \"2016-04-04\", \"2016-04-11\", \"2016-04-15\"]\n",
    "    \n",
    "    comment_date_end = train_end_date\n",
    "    comment_date_begin = comment_date[0]\n",
    "    \n",
    "    for date in reversed(comment_date):\n",
    "        if date < comment_date_end:\n",
    "            comment_date_begin = date\n",
    "        \n",
    "    \n",
    "    buy_action = actions[(actions.time >= train_end_date) & (actions.time < test_end_date) & (actions['type'] == 4)]\n",
    "    buy_action = buy_action.groupby(['user_id', 'sku_id'], as_index=False).sum()\n",
    "    buy_action['label'] = 1 \n",
    "    buy_action = buy_action[['user_id', 'sku_id', 'label']]\n",
    "    \n",
    "    \n",
    "    comment = comment[(comment.dt >= comment_date_begin) & (comment.dt < comment_date_end)]\n",
    "    \n",
    "    \n",
    "    actions = actions[(actions.time >= train_start_date) & (actions.time < train_end_date)]\n",
    "    #comment = comment[]\n",
    "    \n",
    "    df = pd.get_dummies(actions['type'],prefix='action')\n",
    "    actions = pd.concat([actions, df], axis=1)\n",
    "    \n",
    "    # 处理时间\n",
    "    actions['datetime'] = actions['time'].map(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\n",
    "    actions['weights'] =  datetime.strptime(train_end_date, '%Y-%m-%d') - actions['datetime']\n",
    "    \n",
    "    #to days\n",
    "    actions['weights'] = actions['weights'].map(lambda x: math.exp(-x.days))\n",
    "    \n",
    "    actions['action_1'] = actions['action_1'] * actions['weights']\n",
    "    actions['action_2'] = actions['action_2'] * actions['weights']\n",
    "    actions['action_3'] = actions['action_3'] * actions['weights']\n",
    "    actions['action_4'] = actions['action_4'] * actions['weights']\n",
    "    actions['action_5'] = actions['action_5'] * actions['weights']\n",
    "    actions['action_6'] = actions['action_6'] * actions['weights']\n",
    "    \n",
    "    \n",
    "    #drop model id\n",
    "    del actions['model_id']\n",
    "    del actions['type']\n",
    "    del actions['time']\n",
    "    del actions['datetime']\n",
    "    del actions['weights']\n",
    "    \n",
    "    actions = actions.groupby(['user_id', 'sku_id', 'cate', 'brand'], as_index=False).sum()\n",
    "    actions = pd.merge(actions, user, how='left', on='user_id')\n",
    "    actions = pd.merge(actions, buy_action, how='left', on=['user_id', 'sku_id'])\n",
    "    actions = pd.merge(actions, comment, how='left', on='sku_id')\n",
    "    actions = actions.fillna(0)\n",
    "    \n",
    "    #actions = pd.merge(actions, comment, how='left', on='user_id')\n",
    "    # process time\n",
    "    \n",
    "    #print actions\n",
    "    #group by \n",
    "    #group_actions = actions.groupby(['user_id', 'sku_id', 'cate', 'brand'])\n",
    "    #actions = group_actions.apply(weighted)\n",
    "    return actions\n",
    "    #sss = group_actions.apply(lambda x : pd.Series([x['action_1'].sum()], index=['sss']))\n",
    "    #print sss\n",
    "    \n",
    "\n",
    "start_date = \"2016-02-01\"\n",
    "end_date = \"2016-02-08\"\n",
    "test_end_date = \"2016-02-12\"\n",
    "#print action_1\n",
    "actions = make_train_set(start_date, end_date, test_end_date, action_1, user, comment)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#buy_action = action_1[(action_1.time >= end_date) & (action_1.time < test_end_date) & (action_1['type'] == 4)]\n",
    "#buy_action = buy_action.groupby(['user_id', 'sku_id'], as_index=False).sum()\n",
    "#len(buy_action.index)\n",
    "#len(actions[actions.label == 1].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "buy_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_date = \"2016-02-08\"\n",
    "end_date = \"2016-02-15\"\n",
    "test_end_date = \"2016-02-19\"\n",
    "#print action_1\n",
    "actions = make_train_set(start_date, end_date, test_end_date, action_1, user, comment)\n",
    "\n",
    "\n",
    "train_data = actions[numerical_columns]\n",
    "\n",
    "for col in categorical_columns:\n",
    "    df = pd.get_dummies(actions[col],prefix=col)\n",
    "    train_data = pd.concat([train_data, df], axis=1)\n",
    "\n",
    "label_data = actions[label_columns]\n",
    "\n",
    "dpred = xgb.DMatrix(train_data)\n",
    "ypred_bst = bst.predict(dpred)\n",
    "actions['predict'] = ypred_bst\n",
    "\n",
    "threadhold = 0.3\n",
    "\n",
    "all_test_actions = actions[actions.predict > threadhold]\n",
    "#len(all_test_actions.index)\n",
    "test_begin_date = \"2016-02-15\"\n",
    "test_end_date = \"2016-02-19\"\n",
    "\n",
    "all_real_actions = action_1[(action_1.time >= test_begin_date) & (action_1.time < test_end_date) & (action_1['type'] == 4)]\n",
    "\n",
    "report(all_test_actions, all_real_actions)\n",
    "\n",
    "#test_actions = all_test_actions.groupby(['user_id', 'sku_id'])['time'].agg({'no':'count'}).reset_index().sort_values(by='no',ascending=False).groupby('user_id').first()\n",
    "\n",
    "#test_actions = test_actions.reset_index()\n",
    "\n",
    "# 下单\n",
    "test_actions = pd.merge(all_test_actions, product, how='inner', on='sku_id')\n",
    "\n",
    "# 购买\n",
    "real_actions = pd.merge(all_real_actions, product, how='inner', on='sku_id')\n",
    "\n",
    "report(test_actions, real_actions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn import metrics\n",
    "\n",
    "dpred = xgb.DMatrix(train_data)\n",
    "ypred_bst = bst.predict(dpred)\n",
    "\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(label_data, ypred_bst)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "#from sklearn.metrics import roc_auc_score\n",
    "#roc_auc_score(label_data, ypred_bst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "action_reg = action_3[(action_3.time >= '2016-04-13') & (action_3.time < '2016-04-16') & (action_3['type'] == 2)]\n",
    "A = action_reg.groupby(['user_id', 'sku_id'])['time'].agg({'no':'count'}).reset_index().sort_values(by='no',ascending=False).groupby('user_id').first()\n",
    "A = action_reg.groupby(['user_id', 'sku_id'])['time'].agg({'no':'count'})\n",
    "A_clean = A.reset_index()[['user_id', 'sku_id']]\n",
    "B = product\n",
    "A_clean[['user_id', 'sku_id']].to_csv('submision.csv', index=False)\n",
    "\n",
    "#A_clean[['user_id', 'sku_id']].to_csv('submision.csv', index=False)\n",
    "#A.head()\n",
    "A_B = pd.merge(A_clean, B, how='inner', on='sku_id')\n",
    "#A_B\n",
    "len(A_B.index)\n",
    "#A_B[['user_id', 'sku_id']].to_csv('submision.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#action_reg.groupby(['user_id', 'sku_id']).count().reset_index()[['user_id', 'sku_id']].to_csv('submisson.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
